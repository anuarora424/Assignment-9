{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice?\n",
        "\n"
      ],
      "metadata": {
        "id": "OMHana2NCVxQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTrc9sAHCL89"
      },
      "outputs": [],
      "source": [
        "Multithreading and multiprocessing are both techniques for parallelism in programming, but each has its strengths depending on the nature of the tasks and the limitations of the environment.\n",
        " Let’s explore the scenarios where each is preferable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenarios Where Multithreading is Preferable"
      ],
      "metadata": {
        "id": "tTV5zFE9CjQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Multithreading is generally best suited for tasks that are I/O-bound and require frequent context switching or data sharing between threads.\n",
        "Here’s when multithreading is ideal:\n",
        "\n",
        "1) I/O-Bound Tasks:\n",
        "\n",
        "Multithreading excels when dealing with tasks that spend a lot of time waiting for external resources, such as disk I/O, network requests, or database operations.\n",
        "Examples include web servers, file I/O, network clients, and scraping large amounts of data from APIs.\n",
        "\n",
        "2) Lightweight Task Parallelism:\n",
        "\n",
        "Since threads share the same memory space, switching between threads has lower overhead than switching between processes.\n",
        "\n",
        "3) Tasks Requiring Shared Memory:\n",
        "\n",
        "Multithreading is suitable for applications that need threads to communicate frequently and share data efficiently, since all threads share the same memory space.\n",
        "Examples include shared data caches or in-memory data processing pipelines within an application.\n",
        "\n",
        "4) Limited Hardware Resources (RAM):\n",
        "\n",
        "Threads are generally lighter on system resources compared to processes, making multithreading more suitable when memory is limited.\n"
      ],
      "metadata": {
        "id": "RIe4v928CgOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenarios Where Multiprocessing is Preferable"
      ],
      "metadata": {
        "id": "m1XVJdS1DKE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Multiprocessing, in contrast, is more effective for CPU-bound tasks that require intensive computation.\n",
        "Here are scenarios where multiprocessing is the better choice:"
      ],
      "metadata": {
        "id": "ZxxK_0VQDMQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1) CPU-Bound Tasks:\n",
        "\n",
        "When tasks are heavily computation-intensive and can run in parallel, multiprocessing takes advantage of multiple CPU cores, allowing each process to run in true parallelism.\n",
        "Ideal for tasks like mathematical computations, image processing, and machine learning training where each task is isolated and can run independently.\n",
        "\n",
        " 2)Avoiding Global Interpreter Lock (GIL) Limitations:\n",
        "\n",
        "In languages like Python, the GIL prevents multiple threads from executing in parallel in the same process. Multiprocessing bypasses the GIL by creating separate memory spaces for each process, enabling true parallel execution of CPU-bound tasks.\n",
        "\n",
        "3)Long-Running, Isolated Tasks:\n",
        "\n",
        "When tasks need to run for an extended period or should be isolated to avoid crashing the main program, using separate processes makes the system more resilient.\n",
        "For example, a web server might spawn separate processes for user-facing tasks that shouldn’t interfere with each other.\n",
        "\n",
        "4) Memory-Intensive Tasks:\n",
        "\n",
        "In cases where tasks need significant memory and isolation, such as data preprocessing or video rendering, multiprocessing allows each process to run independently without risking memory conflicts.\n",
        "\n",
        "5)Fault Isolation:\n",
        "\n",
        "Because each process has its memory space, crashes in one process won’t affect others.\n",
        "This is useful for applications that need robustness and should continue running even if one part fails.\n"
      ],
      "metadata": {
        "id": "DKtnLRjCDPW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Summary"
      ],
      "metadata": {
        "id": "dEEzbgapDkYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Multithreading is optimal for I/O-bound tasks with frequent communication and data sharing between threads, especially when memory resources are limited.\n",
        "\n",
        "Multiprocessing is preferable for CPU-bound tasks, memory-intensive applications, or when there’s a need to bypass the GIL, isolate tasks for resilience, or use true parallelism across cores."
      ],
      "metadata": {
        "id": "qOaM74etDlPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Both multithreading and multiprocessing have their places, and the choice depends on the specific needs of the task, hardware constraints,\n",
        "and language characteristics."
      ],
      "metadata": {
        "id": "hXrSOhrTDrQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Describe what a process pool is and how it helps in managing multiple processes efficiently?"
      ],
      "metadata": {
        "id": "y--AQHoQDv-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A process pool is a programming construct used in concurrent programming to manage and distribute tasks across multiple processes efficiently.\n",
        "It works by maintaining a collection (or pool) of worker processes that can execute tasks in parallel.\n",
        "This allows the system to manage multiple tasks or jobs simultaneously by assigning each task to an available worker in the pool,\n",
        "rather than creating and destroying new processes for each task, which can be resource-intensive and slow.\n"
      ],
      "metadata": {
        "id": "fjPxFzX0D7mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Here’s how a process pool contributes to efficiency:\n",
        "\n",
        "1) Reduced Overhead: Creating and destroying processes repeatedly can be costly, as process creation involves allocating system resources, memory, and CPU time.\n",
        " A process pool maintains a fixed number of processes that can be reused for multiple tasks,\n",
        " reducing the overhead associated with process creation and termination.\n",
        "\n",
        "2)Resource Limiting: By setting a maximum number of processes in the pool, a process pool prevents excessive resource usage that could lead to system strain.\n",
        " For instance, if a system has 4 CPU cores, setting a process pool to 4 processes allows optimal CPU utilization without overwhelming the system.\n",
        "\n",
        "3) Load Balancing: The pool manager handles the distribution of tasks among the available worker processes, ensuring an even workload across all workers.\n",
        " When a worker completes a task, it becomes available to take on another, promoting efficient use of system resources.\n",
        "\n",
        "4)Parallel Processing: Tasks assigned to different processes can run in parallel, which is particularly useful for CPU-bound tasks that benefit from running\n",
        " simultaneously on multiple cores. This speeds up task execution compared to running them sequentially.\n",
        "\n",
        "In Python, the multiprocessing module offers a Pool class that allows developers to easily implement process pools, making parallel processing\n",
        " straightforward by abstracting much of the complexity involved in process management.\n"
      ],
      "metadata": {
        "id": "KcxoVE8XEAXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain what multiprocessing is and why it is used in Python programs?\n",
        "\n"
      ],
      "metadata": {
        "id": "H5orKaqEEa2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Multiprocessing is a programming technique used to run multiple processes simultaneously, where each process runs in its own Python interpreter and system\n",
        " resources. This approach takes advantage of multiple CPU cores, allowing a program to perform multiple tasks at the same time. In Python,\n",
        "  the multiprocessing module enables you to create separate processes, each with its own memory space, to run tasks concurrently.\n"
      ],
      "metadata": {
        "id": "kwSn0oLuEsJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why Multiprocessing is Used in Python Programs\n"
      ],
      "metadata": {
        "id": "0xx1maWxEyFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Bypassing the Global Interpreter Lock (GIL): Python’s Global Interpreter Lock (GIL) restricts a single Python interpreter to execute only one thread at a time.\n",
        " This limitation can slow down programs that need to perform many tasks in parallel, especially on multicore systems. By creating separate processes,\n",
        "  each with its own Python interpreter, multiprocessing overcomes the GIL, enabling true parallelism.\n"
      ],
      "metadata": {
        "id": "pItMZZ7vE3Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2. Improving Performance for CPU-Bound Tasks: Multiprocessing is particularly useful for CPU-bound tasks (like mathematical computations, data processing,\n",
        "  and image processing) because each process can be assigned to a different CPU core. This setup enables these tasks to be completed faster\n",
        "   than if they were executed sequentially."
      ],
      "metadata": {
        "id": "YG-1LDg6E-fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3. Simpler Parallelism Management: The multiprocessing module abstracts much of the complexity associated with process management, providing tools for creating,\n",
        " controlling, and communicating between processes. It simplifies developing concurrent applications and managing resources effectively.\n"
      ],
      "metadata": {
        "id": "kc5pVKO9FHY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "By leveraging multiprocessing, Python programs can perform tasks more efficiently, especially in scenarios where computational power is critical.\n"
      ],
      "metadata": {
        "id": "HyrbqPouFOA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_sVpHPe4FQze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here’s a Python program that demonstrates multithreading with a Lock to avoid race conditions. In this example,\n",
        "one thread will add numbers to a shared list, while another thread will remove numbers from the list.\n"
      ],
      "metadata": {
        "id": "EqQmDCfHFQbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared list\n",
        "shared_list = []\n",
        "\n",
        "# Lock for synchronizing access to shared_list\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function for adding numbers to the list\n",
        "def add_numbers():\n",
        "    for i in range(10):\n",
        "        with lock:  # Lock is acquired before modifying the list\n",
        "            shared_list.append(i)\n",
        "            print(f\"Added {i} to the list\")\n",
        "        time.sleep(0.1)  # Simulate a delay\n",
        "\n",
        "# Function for removing numbers from the list\n",
        "def remove_numbers():\n",
        "    for _ in range(10):\n",
        "        with lock:  # Lock is acquired before modifying the list\n",
        "            if shared_list:\n",
        "                removed_item = shared_list.pop(0)\n",
        "                print(f\"Removed {removed_item} from the list\")\n",
        "        time.sleep(0.15)  # Simulate a delay\n",
        "\n",
        "# Create threads\n",
        "thread1 = threading.Thread(target=add_numbers)\n",
        "thread2 = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start threads\n",
        "thread1.start()\n",
        "thread2.start()\n",
        "\n",
        "# Wait for threads to complete\n",
        "thread1.join()\n",
        "thread2.join()\n",
        "\n",
        "print(\"Final list:\", shared_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70kHqPFXFkAn",
        "outputId": "2f9ca44d-eb1a-4ddf-f34e-632ca53078b7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 0 to the list\n",
            "Removed 0 from the list\n",
            "Added 1 to the list\n",
            "Removed 1 from the list\n",
            "Added 2 to the list\n",
            "Added 3 to the list\n",
            "Removed 2 from the list\n",
            "Added 4 to the list\n",
            "Removed 3 from the list\n",
            "Added 5 to the list\n",
            "Added 6 to the list\n",
            "Removed 4 from the list\n",
            "Added 7 to the list\n",
            "Removed 5 from the list\n",
            "Added 8 to the list\n",
            "Added 9 to the list\n",
            "Removed 6 from the list\n",
            "Removed 7 from the list\n",
            "Removed 8 from the list\n",
            "Removed 9 from the list\n",
            "Final list: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Explanation\n",
        "1) shared_list: The shared resource where numbers are added or removed.\n",
        "\n",
        "2) lock: A threading.Lock() object that synchronizes access to the shared_list, preventing race conditions.\n",
        "\n",
        "3) add_numbers(): Adds numbers to the list while holding the lock.\n",
        "\n",
        "4) remove_numbers(): Removes numbers from the list, also while holding the lock.\n",
        "\n",
        "5) Threads: Two threads are created and started, each running one of the above functions.\n"
      ],
      "metadata": {
        "id": "8KeVNi_8FoFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Output\n",
        "You should see interleaved \"Added\" and \"Removed\" messages, and the lock ensures they don’t interfere with each other.\n"
      ],
      "metadata": {
        "id": "kK5tqFv2F4Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Describe the methods and tools available in Python for safely sharing data between threads and processes?\n"
      ],
      "metadata": {
        "id": "yC-JqqgeF7hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "In Python, safely sharing data between threads and processes is crucial to avoid data corruption and achieve concurrency.\n",
        " The following methods and tools are available to handle shared data effectively in multithreaded and multiprocessing contexts:\n"
      ],
      "metadata": {
        "id": "NI3JusRQGCkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1) Threading Synchronization Primitives\n",
        "\n",
        "The threading module in Python provides various synchronization tools that ensure safe data sharing among threads. These are primarily used to avoid race conditions in shared memory.\n",
        "\n",
        "Locks (threading.Lock): A basic mutual exclusion lock that allows only one thread to access a shared resource at a time. A thread must acquire the lock before accessing the resource and release it afterward.\n",
        "\n",
        "RLocks (threading.RLock): A reentrant lock that can be acquired multiple times by the same thread, useful in recursive or nested locking scenarios.\n",
        "\n",
        "Semaphores (threading.Semaphore): Controls access to a shared resource through a counter, allowing a fixed number of threads to hold the semaphore simultaneously.\n",
        "\n",
        "Events (threading.Event): Allows threads to wait for an event to occur. It’s useful for signaling between threads without sharing data directly.\n",
        "\n",
        "Condition Variables (threading.Condition): Provides a way for threads to wait for some condition to be met. It is often used with Lock or RLock to ensure only one thread is active at a time when a condition is being checked or updated.\n"
      ],
      "metadata": {
        "id": "diD181p6GYfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2) Queues\n",
        "\n",
        "Python’s queue module (for threads) and multiprocessing.Queue (for processes) provide thread-safe and process-safe queue implementations. These queues facilitate safe data sharing by handling locking internally.\n",
        "\n",
        "Threading Queue (queue.Queue): Thread-safe, designed specifically for inter-thread communication. It supports FIFO, LIFO, and priority queues.\n",
        "\n",
        "Multiprocessing Queue (multiprocessing.Queue): Allows safe data sharing between processes. Unlike queue.Queue, it is suitable for inter-process communication because it uses shared memory or pipes internally.\n"
      ],
      "metadata": {
        "id": "dzISCJE0Gh8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3) Shared Memory in Multiprocessing\n",
        "For multiprocessing, Python provides shared memory support for fast data sharing between processes without the need for data serialization (pickling/unpickling). This is available via the multiprocessing and multiprocessing.shared_memory modules.\n",
        "\n",
        "Value and Array (multiprocessing.Value and multiprocessing.Array): Used to share data across processes by creating a shared memory space where variables or arrays are stored. Access to these shared resources can be controlled using locks to prevent race conditions.\n",
        "\n",
        "Shared Memory (multiprocessing.shared_memory.SharedMemory): Allows for direct shared memory access without additional memory copying, useful for large data that multiple processes need to access concurrently.\n",
        "\n"
      ],
      "metadata": {
        "id": "WDrHI71FGpQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4) Manager-Based Shared Objects\n",
        "The multiprocessing.Manager class provides a high-level interface for sharing more complex objects like dictionaries, lists, and other custom data structures across processes.\n",
        "\n",
        "Manager: A manager object can create shared objects (e.g., Manager().list(), Manager().dict()) that allow multiple processes to interact with them as if they were local objects. Managers ensure data integrity with internal synchronization mechanisms.\n"
      ],
      "metadata": {
        "id": "6e_ykN1MGuMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5) Concurrent Collections in concurrent.futures\n",
        "\n",
        "concurrent.futures Module: This module provides high-level abstractions for managing threads (ThreadPoolExecutor) and processes (ProcessPoolExecutor).\n",
        " Although it doesn't provide direct shared data structures, it simplifies safe sharing of data through task-based parallelism and result collection.\n"
      ],
      "metadata": {
        "id": "OBsQ5UK1G0k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "6)  Atomic Operations (in the threading module)\n",
        "Atomic Variables: Python's Global Interpreter Lock (GIL) generally provides thread-safety for simple atomic operations on built-in types (e.g., +=, -=)\n",
        " but not for compound operations. For example, you might use the AtomicCounter or Queue objects to perform compound operations safely,\n",
        "  avoiding complex synchronization requirements.\n"
      ],
      "metadata": {
        "id": "jWH9YSZ9G6ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "7) Third-Party Libraries (e.g., multiprocess and asyncio)\n",
        "Multiprocess Library: An extension of Python’s multiprocessing module with advanced sharing options, enabling complex data structures and more flexible\n",
        "inter-process communication.\n",
        "\n",
        "Asyncio: While primarily for asynchronous programming, asyncio offers Locks, Events, Queues, and Conditions which allow asynchronous coroutines to wor\n",
        "k together with safe shared data access.\n"
      ],
      "metadata": {
        "id": "aWd4XCJHH-Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Summary\n",
        "The Python standard library provides robust tools for safely sharing data in multithreading (threading and queue modules) and multiprocessing\n",
        " (multiprocessing module). By choosing the appropriate tool (locks, queues, shared memory, etc.), developers can control access to shared resources and\n",
        "  avoid data corruption, ensuring thread- and process-safe operations.\n"
      ],
      "metadata": {
        "id": "mkQCg4x0JwPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so?\n",
        "\n"
      ],
      "metadata": {
        "id": "SEcto6LgJ9Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Handling exceptions in concurrent programs is critical for maintaining the stability, reliability, and performance of the application.\n",
        "In a concurrent program, multiple tasks or threads operate simultaneously, so an unhandled exception in one thread could disrupt other threads,\n",
        "lead to resource leaks, or cause the entire application to crash. Additionally, debugging concurrent programs is notoriously challenging due to the potential\n",
        " for race conditions, deadlocks, and the difficulty of reproducing errors consistently.\n"
      ],
      "metadata": {
        "id": "8N08Rt9xJ8_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Here are several key reasons and techniques for handling exceptions in concurrent programs:\n"
      ],
      "metadata": {
        "id": "EAmcph4DKPW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1) Ensuring Application Stability\n",
        "In a concurrent environment, an exception in one task can propagate and cause the failure of other tasks, especially if they share resources. For example, a failure in a thread that locks a shared resource can lead to deadlocks if not handled properly.\n",
        "To avoid such disruptions, handling exceptions ensures that failures in individual tasks are contained, allowing the program to continue running or shut down gracefully.\n"
      ],
      "metadata": {
        "id": "2ZGHaLMVKUhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2) Avoiding Resource Leaks\n",
        "Threads or tasks in concurrent programs often acquire resources (e.g., memory, file handles, network connections).\n",
        "If an exception occurs without proper handling, these resources might not be released, causing memory leaks or leaving files and connections open.\n",
        "Exception handling can ensure that resources are released correctly even when tasks fail, which is essential for maintaining resource\n",
        "efficiency and preventing bottlenecks.\n"
      ],
      "metadata": {
        "id": "-ngOAU-vKahW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3) Techniques for Exception Handling in Concurrent Programs\n",
        "a. Structured Exception Handling (Try-Catch Blocks)\n",
        "Use try-catch blocks within individual tasks or threads to capture exceptions and handle them locally.\n",
        " This is useful for scenarios where each task has specific error-handling requirements.\n",
        "Ensuring each task has its own error-handling mechanism can prevent localized failures from propagating.\n"
      ],
      "metadata": {
        "id": "JQc231NsKfwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.)  Future and Promise-Based Handling\n",
        "In languages that support futures or promises (e.g., Java’s CompletableFuture, Python’s concurrent.futures), exceptions can be captured and propagated back to the calling thread.\n",
        "Future objects can also support methods like get or join that allow the main thread to check the outcome and handle exceptions as part of the task's result.\n",
        "\n",
        "c.) Centralized Exception Handling with Thread Pools\n",
        "When using a thread pool, it's often beneficial to have a central point for exception handling, typically by overriding the thread pool’s uncaughtExceptionHandler.\n",
        "This allows the program to detect uncaught exceptions from all threads in the pool and decide on a common error-handling strategy, such as logging the error,\n",
        " retrying the task, or shutting down the pool gracefully.\n",
        "\n",
        "d) Using Supervisors (In Actor-Based Models)\n",
        "Actor-based concurrency models (e.g., in Akka) often implement supervisors that monitor the health of child actors. When an actor throws an exception, its supervisor can decide to restart the actor, escalate the exception, or stop the actor based on predefined policies.\n",
        "This technique isolates failure and recovery to specific actors, improving fault tolerance without affecting unrelated parts of the program.)\n",
        "\n",
        "e) Custom Error Handlers and Callbacks\n",
        "Some concurrent frameworks allow you to attach error handlers or callbacks that execute when an exception occurs. For instance, in Python’s asyncio framework,\n",
        " exception handlers can be added to handle uncaught exceptions in asynchronous tasks.\n",
        "Callbacks allow the developer to define custom behavior in response to errors, such as retrying a task or logging the error in a specific format.\n"
      ],
      "metadata": {
        "id": "4ogjqkKNKkY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4. Logging and Monitoring\n",
        "\n",
        "Even when exceptions are handled properly, logging is crucial for diagnosing issues in concurrent programs. Without proper logging,\n",
        " it may be difficult to trace the source of a problem, especially in production systems where reproducing concurrency issues can be challenging.\n",
        "Exception handling can be enhanced with monitoring tools that provide real-time insights into errors and help detect patterns in failures across tasks.\n",
        "By implementing these techniques, developers can improve the robustness and maintainability of concurrent programs, ensuring that exceptions are handled effectively without compromising application performance or stability.\n",
        "\n"
      ],
      "metadata": {
        "id": "e3ukc8tDK4hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently Use concurrent.futures.ThreadPoolExecutor to manage the threads?\n",
        "\n"
      ],
      "metadata": {
        "id": "4HvDfBoVLEBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here’s a Python program that uses concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently."
      ],
      "metadata": {
        "id": "FNZK8Ce8LQvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import math\n",
        "\n",
        "# Function to calculate the factorial\n",
        "def calculate_factorial(n):\n",
        "    result = math.factorial(n)\n",
        "    print(f\"Factorial of {n} is {result}\")\n",
        "    return result\n",
        "\n",
        "# Main function to run factorial calculations in a thread pool\n",
        "def main():\n",
        "    # Create a thread pool with a suitable number of workers\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        # Submit tasks to the thread pool for numbers 1 to 10\n",
        "        futures = [executor.submit(calculate_factorial, i) for i in range(1, 11)]\n",
        "\n",
        "        # Retrieve results (if needed)\n",
        "        results = [future.result() for future in futures]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O733xGzLeCl",
        "outputId": "1592da90-a54a-4d6a-8d9f-1d6582bd8b97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 1 is 1Factorial of 2 is 2\n",
            "Factorial of 3 is 6\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Explanation\n",
        "\n",
        "Function calculate_factorial(n): Computes the factorial of a given number\n",
        "\n",
        "Thread pool: Created using ThreadPoolExecutor(max_workers=5), where you can adjust max_workers based on your preference.\n",
        "Tasks submission: Each factorial calculation from 1 to 10 is submitted to the executor, and results are printed as they are computed.\n",
        "Result retrieval: Each future.result() call waits for its corresponding factorial calculation to complete.\n",
        "This setup allows for concurrent computation, improving efficiency when dealing with multiple tasks.\n"
      ],
      "metadata": {
        "id": "X_5XToWsLgkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes)?\n"
      ],
      "metadata": {
        "id": "fOYM0SBXMb6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here's a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10:\n"
      ],
      "metadata": {
        "id": "JrB6UovhL9ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def square_number(n):\n",
        "    return n * n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a list of numbers from 1 to 10\n",
        "    numbers = list(range(1, 11))\n",
        "\n",
        "    # Create a multiprocessing Pool with the number of processes equal to the number of CPU cores\n",
        "    with multiprocessing.Pool() as pool:\n",
        "        # Map the square_number function to the numbers list\n",
        "        results = pool.map(square_number, numbers)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"Squares of numbers from 1 to 10:\", results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsxawdR2Ngwt",
        "outputId": "17a395e9-8623-4d14-fc2c-a036bbda23ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Squares of numbers from 1 to 10: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Explanation\n",
        "\n",
        "square_number function computes the square of a given number.\n",
        "The multiprocessing.Pool() is created, which manages a pool of worker processes.\n",
        "pool.map(square_number, numbers) applies the square_number function to each element in the numbers list in parallel.\n",
        "Finally, it prints the list of squares.\n"
      ],
      "metadata": {
        "id": "kvdAsZNdNiV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Expected Output"
      ],
      "metadata": {
        "id": "mW1pFmDgPHr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Squares of numbers from 1 to 10: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
      ],
      "metadata": {
        "id": "n_dISWtTPJg8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}